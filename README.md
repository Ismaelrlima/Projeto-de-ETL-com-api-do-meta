# ğŸ“Š Meta Ads ETL + Banco + BI (Analytics Engineering Endâ€‘toâ€‘End)

Pipeline **end-to-end** de **Analytics Engineering** que coleta dados da **API do Meta (Facebook/Instagram Ads)**, realiza **ETL em Python**, persiste em **banco relacional** e disponibiliza a camada de dados para **consumo por BI** (dashboards e relatÃ³rios).

âœ… **OrquestraÃ§Ã£o diÃ¡ria com Jenkins** (job agendado) para manter os dados sempre atualizados.

---

## ğŸ¯ O que este projeto entrega (visÃ£o de Analytics Engineer)

- **IngestÃ£o via API** (Meta Ads)
- **TransformaÃ§Ãµes e padronizaÃ§Ãµes** para anÃ¡lise
- **Carga no banco (UPSERT/MERGE)** para manter histÃ³rico e evitar duplicidade
- **Modelagem analÃ­tica** por tabelas (dimensÃ£o + fatos)
- **Camada de BI** consumindo do banco para dashboards/KPIs
- **AutomaÃ§Ã£o diÃ¡ria** com Jenkins

---

## ğŸ§  Arquitetura

```text
API do Meta
    â†“
ETL (Python) â€” extract â†’ transform â†’ load
    â†“
Banco Relacional (PostgreSQL recomendado)
    â†“
BI (Power BI / Looker / Tableau / Metabase)
```

---

## ğŸ—ƒï¸ Tabelas geradas no banco

O pipeline grava (por padrÃ£o) trÃªs entidades no banco:

- **`ads_dimension`** â†’ dimensÃ£o com mapeamentos de **IDs e nomes** (base para joins e leitura humana)
- **`ads_campaign_performance`** â†’ **performance agregada** (nÃ­vel de campanha/insights)
- **`ads_lead_insights`** â†’ **leads em alta granularidade** (insights/demografia/geografia)

> Os nomes das tabelas estÃ£o definidos em `src/main.py` e podem ser ajustados conforme sua modelagem.

---

## ğŸ“‚ Estrutura do repositÃ³rio

```text
ğŸ“¦src
 â”£ ğŸ“‚dimensao
 â”ƒ â”£ ğŸ“œpipeline.py
 â”ƒ â”— ğŸ“œ__init__.py
 â”£ ğŸ“‚leads
 â”ƒ â”£ ğŸ“œpipeline.py
 â”ƒ â”— ğŸ“œ__init__.py
 â”£ ğŸ“‚performance
 â”ƒ â”£ ğŸ“œpipeline.py
 â”ƒ â”— ğŸ“œ__init__.py
 â”£ ğŸ“œextract.py
 â”£ ğŸ“œload.py
 â”£ ğŸ“œmain.py
 â”£ ğŸ“œtransform.py
 â”— ğŸ“œ__init__.py
```

---

## âœ… PrÃ©-requisitos

- Python 3.10+ (recomendado)
- Acesso/credenciais da **API do Meta**
- Banco de dados (PostgreSQL recomendado)
- (ProduÃ§Ã£o) Jenkins para agendamento diÃ¡rio

---

## ğŸ” ConfiguraÃ§Ã£o (.env)

1) Crie um arquivo `.env` na raiz (ou injete variÃ¡veis no Jenkins) usando o modelo:

```bash
cp .env.example .env
```

2) Preencha os campos:

- **Meta API**: `APP_ID`, `APP_SECRET`, `ACCESS_TOKEN`, `AD_ACCOUNT_ID`
- **DB**: `DB_DIALECT`, `DB_DRIVER`, `DB_USER`, `DB_PASS`, `DB_HOST`, `DB_PORT`, `DB_NAME`

---

## â–¶ï¸ Como executar localmente

### 1) Instalar dependÃªncias
```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 2) Rodar o fluxo completo (recomendado)
```bash
python -m src.main
```

### 3) Rodar pipelines isolados (opcional)
```bash
python -m src.dimensao.pipeline
python -m src.performance.pipeline
python -m src.leads.pipeline
```

---

## ğŸ¤– OrquestraÃ§Ã£o com Jenkins (diÃ¡rio)

Este repositÃ³rio jÃ¡ inclui um **`Jenkinsfile`** com agendamento diÃ¡rio via `cron()` e execuÃ§Ã£o do comando:

```bash
python -m src.main
```

**Boas prÃ¡ticas sugeridas no Jenkins:**
- Guardar `.env` via **Credentials** (Secret file / Secret text)
- Persistir logs em `logs/` (se vocÃª gerar arquivos de log)
- Notificar falhas (Slack/Email) para garantir confiabilidade do pipeline

---

## ğŸ“Š Camada de BI (fechando o ciclo)

O banco alimentado por este ETL serve como **fonte Ãºnica de verdade** para dashboards de BI, permitindo:
- Monitoramento de KPIs (leads, custo, cliques, conversÃµes)
- Comparativos por perÃ­odo (dia/semana/mÃªs)
- AnÃ¡lises por campanha/conjunto/anÃºncio (dependendo da granularidade coletada)
- VisÃ£o operacional + visÃ£o gerencial

> Em um projeto completo de **Analytics Engineer**, o valor final se materializa justamente aqui: **dados confiÃ¡veis no BI**.

---

## ğŸ§© ObservaÃ§Ãµes importantes

- O fluxo principal roda em sequÃªncia: **dimensÃ£o â†’ performance â†’ leads**
- O mÃ³dulo `src/load.py` implementa carga com estratÃ©gia de **UPSERT** (mantÃ©m dados atualizados sem duplicar)
- Ajuste o perÃ­odo de coleta (`TOTAL_DAYS_*`) em `src/main.py` conforme sua necessidade (histÃ³rico vs. incremental)

---

## ğŸ›£ï¸ PrÃ³ximas evoluÃ§Ãµes (ideias)

- Testes de qualidade de dados (ex.: Great Expectations)
- Monitoramento/alertas (ex.: falhas de API, volume anÃ´malo)
- Camada semÃ¢ntica para BI (mÃ©tricas padronizadas)
- MigraÃ§Ã£o para Data Warehouse (se crescer volume/complexidade)

---

## ğŸ§‘â€ğŸ’» Autor

Projeto desenvolvido para consolidar um pipeline completo de **Analytics Engineering** (API â†’ ETL â†’ DB â†’ BI + OrquestraÃ§Ã£o diÃ¡ria).
